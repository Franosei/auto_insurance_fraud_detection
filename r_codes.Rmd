---
title: "auto_insurance"
author: "Francis Osei"
date: "2022-12-22"
output: html_document
---

```{r}
#remotes::install_github("coolbutuseless/threed")
#remotes::install_github("coolbutuseless/ggthreed")
library(threed)
library(ggthreed)
library(data.table)
library(dplyr)
library(tidyverse)
library(miscset)
library(lares)
library(caret)
library(ggplot2)
library(ROSE)
library(randomForest)
library(e1071)
library(plotrix)
library(naivebayes)
```

```{r}
data <- fread("https://raw.githubusercontent.com/Franosei/auto_insurance_fraud_detection/main/insurance_claims.csv")
head(data,5)
```
# Data preprocessing
## Checking for mising values
Here we try to find all columns with mising values and count how many missing values each column has. We realised that the colunm `_c39` has 1000 column so we drop that column


```{r}
#checking for columns with NA
Na_column <- names(which(sapply(data, anyNA)))
count_c39 <- sum(is.na(data$`_c39`))
data = subset(data, select = -c(`_c39`) )
head(data,5)
```

## Unique element for each column

Categorical values with interger data types are easy to deal with and easy to undersatnd. From our dataset we can observe that those are the number of times an event occurs, year, age or amount. 
We focus on the the unique element for object character. This will give us the idea whether to do one_hot_encoding or label_encoding. Both methods has their own advantages and disadvantages. We can observe that the column "incident_location" is different for all policy holders so we can drop that column. 
We then tried to see some of the unique value for some columns.

```{r}
data_char <- data %>% 
  select_if(is.character) %>% 
  apply(2, function(x) length(unique(x)))
data_char
```
# Needed columns

We can observed that columns like "policy_bind_date", "policy_number", "insured_zip", "incident_location". These columns doesnt not contain information that will help in our machine learning model. "incident_location" contains 1000 unique locations. We will now focus on the needed columns and convert all character datatype to factor(class). "policy_bind_date" could have been useful to generate a new column but we have "months_as_customer" which show the difference between the "policy_bind_date" and the "incidence_date"

```{r}
new_data <- data %>% 
  subset(select = -c(policy_bind_date,policy_number,insured_zip,incident_location))
new_data <- as.data.frame(unclass(new_data), stringsAsFactors = TRUE)
head(new_data,5)
```
# Data Visualization
## Distribution of the categorical variables


```{r}
data_fac <- new_data %>% 
  select_if(is.factor)
data_fac
```

```{r,fig.width = 13,fig.height = 7}
data_fac %>% 
  pivot_longer(cols = c(1:10), names_to = "variables") %>% 
  ggplot(aes(y=value,fill = fraud_reported))+
  geom_bar()+
  scale_fill_manual(values=c("orange", "darkred"))+
  coord_flip()+
  facet_wrap(~variables, scale = "free", ncol = 5)+
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  theme(axis.title.x = element_blank())+
  theme(legend.position = "bottom")
```
```{r,fig.width = 13,fig.height = 7}
data_fac %>% 
  pivot_longer(cols = c(11:17), names_to = "variables") %>% 
  ggplot(aes(y=value,fill = fraud_reported))+
  geom_bar()+
  scale_fill_manual(values=c("orange", "darkred"))+
  coord_flip()+
  facet_wrap(~variables, scale = "free", ncol = 4)+
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  theme(axis.title.x = element_blank())+
  theme(legend.position = "bottom")
```
Everything looks fine for each class in each column except that there is are columns having "?" as a class so we tried to filter all those class and rename it as "unknown". Those columns cannot be remove becuase it might indicate that the insurer that class is not yet decided. Is better to keep then as a class than treating them as missing data. This might also means that the policy holder refuses to answer those questions. We will deal with this prolem when dealing with label encoding and the one-hot-encoding

## Distibution plot for non categorical features

Before we start to visualize the numeric columns, Using the "auto_date" in building our model will not have any impact on feature prediction if a new auto is bought after the latest year in our dataset. This problem can be solve in general by adding the policy holder to your training data and retrain your model. To avoid all these we will create a new column which takes the difference between the "auto_year" and "incidence_year". This is more robust and reproducible in building a machine learning model.

```{r}
new_data$incident_date <- as.integer(format(new_data$incident_date, format="%Y"))
new_data <- new_data %>% 
  mutate(auto_year_diff_incidence_year = abs(auto_year-incident_date)) %>% 
  select(-c(incident_date,auto_year))
```

Now we can plot the distribution of the non categorical variables

```{r,fig.width = 13,fig.height = 7}
non_cat <- select(new_data, -c(colnames(data_fac)))
non_cat$fraud_reported <- data_fac$fraud_reported
non_cat %>% 
  pivot_longer(cols = c(1:8), names_to = "variables") %>% 
  ggplot(aes(y=value,fill = fraud_reported))+
  geom_histogram()+
  scale_fill_manual(values=c("orange", "darkred"))+
  coord_flip()+
  facet_wrap(~variables, scale = "free", ncol =4)+
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  theme(axis.title.x = element_blank())+
  theme(legend.position = "none")
```

```{r,fig.width = 13,fig.height = 7}
non_cat %>% 
  pivot_longer(cols = c(9:16), names_to = "variables") %>% 
  ggplot(aes(y=value,fill = fraud_reported))+
  geom_histogram()+
  scale_fill_manual(values=c("orange", "darkred"))+
  coord_flip()+
  facet_wrap(~variables, scale = "free", ncol =4)+
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  theme(axis.title.x = element_blank())+
  theme(legend.position = "none")
```
Now before we proced futhure to build our machine learning model, we will like to perform one-hot-encoding and label encoding to our categorical fetures.

## label encoding

```{r}
levels(new_data$insured_sex) <- c(1,0)
new_data$insured_sex <- as.integer(as.character(new_data$insured_sex))
levels(new_data$insured_education_level) <- c(2,3,1,5,4,6,7)
new_data$insured_education_level <- as.integer(as.character(new_data$insured_education_level))
levels(new_data$incident_severity) <- c(3,2,4,1)
new_data$incident_severity <- as.integer(as.character(new_data$incident_severity))
levels(new_data$fraud_reported) <- c(0,1)
new_data$fraud_reported <- as.integer(as.character(new_data$fraud_reported))
```

## One-hot-encoding
```{r}
levels(new_data$property_damage) <- c("Unknown","NO","YES")
levels(new_data$collision_type) <- c("Unknown","Front Collision","Rear Collision","Side Collision")
levels(new_data$police_report_available) <- c("Unknown","NO","YES")
dummy <- dummyVars(" ~ .", data=new_data)
final_df <- data.frame(predict(dummy, newdata=new_data))
```

# Top 20 correlated varables 

```{r,r,fig.width = 13,fig.height = 7}
corr_cross(final_df,
  max_pvalue = 0.05,
  top = 20
)
```

```{r}
data_cor <- cor(final_df[ , colnames(final_df) != "fraud_reported"],final_df$fraud_reported)
data_cor     
```
# Machine Learning
##  Splitting dataset into training and testing data
 
We will first split our dataset into training and test data. We will use 70\% of our data for training and 30\% for testing our machine learning model
```{r}
set.seed(123)
ind <- sample(2, nrow(final_df), replace = TRUE, prob = c(0.7, 0.3))
train <- final_df[ind==1,]
test <- final_df[ind==2,]
```


## Balancing the train dataset
To avoid data leakage, we will we will balance the train dataset instead of balancing our whole dataset. Balancing our training dataset helps prevent the model from becoming biased towards one class. Having a balanced dataset would generate higher accuracy models, higher balanced accuracy and balanced detection rate. c("24%","76%")

```{r}
tag <- train %>% 
  select(fraud_reported)
tag[,'fraud_reported']<-factor(tag[,'fraud_reported'])
sub_tag <- tag %>% group_by(fraud_reported) %>% 
  mutate(count = round(n()/nrow(train),2)*100) %>% 
  distinct() 
pie3D(sub_tag$count,radius=1.5,labels = c("24%","76%"),explode = 0.1, col=c("darkred","orange"))
legendg(0.3,1.2,c("fraud","not fraud"),fill=c("darkred","orange"))
```

## Over Sampling
Here we randomly select data points from the minority class (Fraud) and duplicate them to increase the number of data points.

```{r}
set.seed(111)
train$fraud_reported <- as.factor(train$fraud_reported)
train_balnce <- upSample(x = train[,-ncol(train)],y = train$fraud_reported)
```


```{r}
tag <- train_balnce %>% 
  select(fraud_reported)
tag[,'fraud_reported']<-factor(tag[,'fraud_reported'])
sub_tag <- tag %>% group_by(fraud_reported) %>% 
  mutate(count = round(n()/nrow(train_balnce),2)*100) %>% 
  distinct() 
pie3D(sub_tag$count,radius=1.5,labels = c("50%","50%"),explode = 0.1, col=c("darkred","orange"))
legendg(0.3,1.2,c("fraud","not fraud"),fill=c("darkred","orange"))
```
# Naive Bayes

```{r}
train_balnce <- scale( train_balnce,-c('fraud_reported'))
model <- naive_bayes(fraud_reported ~ ., data = train_balnce, usekernel = T) 
p1 <- predict(model, train_balnce)
tab1 <- table(p1, train_balnce$fraud_reported)
sum(diag(tab1)) / sum(tab1)
```

